{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab37b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -5.1498,  -2.7176,  -3.2868,  ...,  -3.2823,  -2.8758,  -5.1768],\n",
       "          [ -3.1193,  -1.2302,  -1.8517,  ...,  -2.1136,  -1.6637,  -3.5740],\n",
       "          [ -3.3186,  -1.4871,  -2.1858,  ...,  -2.4324,  -1.7634,  -3.7822],\n",
       "          ...,\n",
       "          [ -6.4785,  -5.4924,  -6.7167,  ...,  -7.6644,  -7.0214,  -7.9190],\n",
       "          [ -5.6967,  -4.3689,  -4.9955,  ...,  -6.7501,  -5.8278,  -7.0935],\n",
       "          [ -7.4101,  -6.2465,  -6.8270,  ...,  -7.7262,  -7.3908,  -8.5184]],\n",
       "\n",
       "         [[ -6.0042,  -3.5639,  -4.2328,  ...,  -4.8786,  -4.0541,  -6.5235],\n",
       "          [ -4.1260,  -2.3674,  -3.0054,  ...,  -3.9989,  -3.4570,  -4.8970],\n",
       "          [ -3.9396,  -2.4210,  -2.9474,  ...,  -4.4821,  -3.6182,  -5.1694],\n",
       "          ...,\n",
       "          [ -5.7659,  -4.6218,  -5.7275,  ...,  -6.6658,  -6.0371,  -6.8169],\n",
       "          [ -4.8387,  -3.5346,  -4.4197,  ...,  -5.9540,  -5.1233,  -6.0878],\n",
       "          [ -7.2266,  -5.3879,  -6.1601,  ...,  -7.0614,  -6.5741,  -8.0243]],\n",
       "\n",
       "         [[ -0.4331,   3.2934,   3.1339,  ...,   3.0697,   3.0559,  -0.3988],\n",
       "          [  2.2608,   4.0964,   4.2258,  ...,   3.9825,   3.8322,   2.2677],\n",
       "          [  2.2832,   4.0678,   4.1626,  ...,   3.6770,   3.8593,   2.3387],\n",
       "          ...,\n",
       "          [ -5.2431,  -4.7675,  -5.9298,  ...,  -7.1131,  -6.8152,  -7.5684],\n",
       "          [ -4.7673,  -3.8521,  -4.5062,  ...,  -6.0634,  -5.6749,  -6.4900],\n",
       "          [ -7.4597,  -5.2113,  -5.5192,  ...,  -7.1045,  -6.7447,  -8.2335]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-10.7659,  -7.5176,  -8.0469,  ...,  -7.7269,  -7.3980, -10.7582],\n",
       "          [ -8.1758,  -5.9099,  -6.5325,  ...,  -6.3605,  -5.9932,  -8.1146],\n",
       "          [ -7.9598,  -5.8591,  -6.4477,  ...,  -6.7157,  -6.3079,  -8.3237],\n",
       "          ...,\n",
       "          [ -9.6958,  -8.1042,  -8.7667,  ...,  -9.4915,  -9.1352,  -9.9888],\n",
       "          [ -8.5302,  -6.9494,  -7.3802,  ...,  -8.8173,  -8.3513,  -9.4285],\n",
       "          [-10.7787,  -9.0579,  -9.5206,  ...,  -9.7654,  -9.6057, -11.7004]],\n",
       "\n",
       "         [[-11.0976,  -8.0227,  -8.7197,  ...,  -8.3916,  -7.7389, -10.6443],\n",
       "          [ -8.7354,  -7.0275,  -7.8997,  ...,  -7.9007,  -7.3937,  -8.9454],\n",
       "          [ -8.6469,  -6.8978,  -7.9207,  ...,  -8.0624,  -7.5833,  -9.2372],\n",
       "          ...,\n",
       "          [ -9.5632,  -8.1105,  -8.8754,  ..., -10.1386,  -9.7968,  -9.7883],\n",
       "          [ -8.2767,  -6.6780,  -7.3462,  ...,  -9.3068,  -8.9295,  -9.2206],\n",
       "          [-10.7274,  -8.7537,  -9.6795,  ..., -10.2781, -10.1497, -11.6811]],\n",
       "\n",
       "         [[-11.6618,  -7.5043,  -8.4090,  ...,  -7.8205,  -7.1650, -10.7959],\n",
       "          [ -8.9366,  -6.2206,  -6.9254,  ...,  -6.9723,  -6.3010,  -8.1138],\n",
       "          [ -8.7731,  -6.0458,  -7.0109,  ...,  -7.2100,  -6.7309,  -8.3747],\n",
       "          ...,\n",
       "          [-11.4862,  -9.9124, -11.1148,  ..., -12.6109, -12.0872, -12.3728],\n",
       "          [ -9.8661,  -8.3189,  -9.3575,  ..., -11.7319, -11.1825, -11.7189],\n",
       "          [-13.0589, -10.2505, -11.4920,  ..., -12.4401, -12.2071, -14.2877]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, BeitForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "image_path = 'Image_data/Examples/trump.png'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_path_GT = 'Image_data/Examples/trump_GT.png'\n",
    "ground_truth = Image.open(image_path_GT).convert(\"RGB\")\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/beit-base-finetuned-ade-640-640\")\n",
    "model = BeitForSemanticSegmentation.from_pretrained(\"microsoft/beit-base-finetuned-ade-640-640\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "# logits are of shape (batch_size, num_labels, height, width)\n",
    "logits = outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3b479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff58954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits to probabilities using softmax\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "# Select the probabilities for the desired class (e.g., class 0)\n",
    "class_probabilities = probabilities[:, 0, :, :]\n",
    "\n",
    "# Convert probabilities to an image\n",
    "class_probabilities_np = class_probabilities.detach().numpy()\n",
    "class_probabilities_np = class_probabilities_np.squeeze()\n",
    "image_array = np.uint8(class_probabilities_np * 255)\n",
    "\n",
    "image = Image.fromarray(image_array, mode=\"L\")  # Create grayscale image\n",
    "\n",
    "# Display or save the image\n",
    "image.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef95ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
