{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab37b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -6.6088,  -5.3934,  -5.9369,  ...,  -4.6914,  -4.0469,  -5.6981],\n",
       "          [ -4.9641,  -4.5037,  -5.2647,  ...,  -3.9726,  -3.3253,  -4.5915],\n",
       "          [ -5.0439,  -4.8048,  -5.6912,  ...,  -4.3475,  -3.6555,  -4.9466],\n",
       "          ...,\n",
       "          [ -4.2251,  -2.3768,  -3.1829,  ...,  -5.1648,  -4.2984,  -5.6928],\n",
       "          [ -3.7389,  -1.6999,  -2.3304,  ...,  -4.0918,  -3.0130,  -4.3465],\n",
       "          [ -5.8259,  -4.0434,  -4.6106,  ...,  -4.3738,  -3.7330,  -5.3745]],\n",
       "\n",
       "         [[ -6.8251,  -5.6812,  -6.3642,  ...,  -5.7964,  -5.0528,  -7.0172],\n",
       "          [ -5.9137,  -5.6669,  -6.6355,  ...,  -6.4343,  -5.6910,  -6.3783],\n",
       "          [ -5.7067,  -5.6937,  -6.6712,  ...,  -6.7312,  -6.1079,  -6.9104],\n",
       "          ...,\n",
       "          [ -4.6730,  -2.9195,  -3.6721,  ...,  -5.3047,  -4.6950,  -6.2710],\n",
       "          [ -4.2098,  -2.4972,  -3.0371,  ...,  -4.8695,  -3.8761,  -5.0921],\n",
       "          [ -6.8663,  -4.3667,  -4.9050,  ...,  -4.7850,  -4.2003,  -6.0953]],\n",
       "\n",
       "         [[ -7.3251,  -6.5667,  -7.4092,  ...,  -5.9757,  -5.6512,  -6.7762],\n",
       "          [ -6.8846,  -7.0233,  -8.3107,  ...,  -6.8645,  -6.7068,  -6.7558],\n",
       "          [ -6.9458,  -7.3444,  -8.6893,  ...,  -7.2795,  -7.3159,  -7.4586],\n",
       "          ...,\n",
       "          [ -7.2317,  -6.6082,  -7.4887,  ...,  -9.3952,  -8.8215,  -9.5775],\n",
       "          [ -6.6474,  -5.6992,  -6.5015,  ...,  -7.9385,  -7.1628,  -7.2777],\n",
       "          [ -9.5216,  -7.2727,  -7.7511,  ...,  -7.4444,  -6.9561,  -8.7050]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-11.7675,  -9.7610, -10.5423,  ..., -11.4029, -10.9826, -12.7049],\n",
       "          [ -9.4210,  -8.6945,  -9.7519,  ..., -11.2423, -10.8837, -11.4144],\n",
       "          [ -9.2917,  -8.7000,  -9.7259,  ..., -11.5628, -11.4477, -11.8995],\n",
       "          ...,\n",
       "          [-10.5095,  -8.6039,  -9.2535,  ...,  -8.8317,  -8.5050,  -9.9626],\n",
       "          [ -9.6564,  -7.9018,  -8.5803,  ...,  -8.2020,  -7.4210,  -8.4047],\n",
       "          [-11.6502,  -9.3567,  -9.7670,  ...,  -7.8085,  -7.3132, -10.0598]],\n",
       "\n",
       "         [[-12.0694, -10.0702, -10.9288,  ..., -11.6220, -10.9966, -12.0703],\n",
       "          [-10.0463,  -9.7798, -10.9947,  ..., -12.0967, -11.7174, -11.7385],\n",
       "          [ -9.7860,  -9.7649, -10.9790,  ..., -12.1711, -12.0708, -12.0050],\n",
       "          ...,\n",
       "          [ -9.1915,  -6.9629,  -7.6237,  ...,  -8.0366,  -8.0645,  -9.1803],\n",
       "          [ -8.1072,  -6.1218,  -6.8284,  ...,  -7.1656,  -6.4252,  -7.6618],\n",
       "          [-10.4615,  -7.7553,  -8.5449,  ...,  -6.5087,  -6.1611,  -9.1468]],\n",
       "\n",
       "         [[-12.5856, -10.2878, -10.8846,  ..., -11.0808, -10.3897, -12.2741],\n",
       "          [-10.8422, -10.1850, -11.0678,  ..., -11.7692, -11.2832, -11.2709],\n",
       "          [-10.6321, -10.1891, -11.2401,  ..., -11.8750, -11.8022, -11.6866],\n",
       "          ...,\n",
       "          [ -8.5603,  -5.5419,  -5.9888,  ...,  -7.8532,  -7.8756,  -9.2038],\n",
       "          [ -7.7879,  -5.0288,  -5.2797,  ...,  -6.8976,  -6.3441,  -7.5427],\n",
       "          [-11.4596,  -7.0121,  -7.5924,  ...,  -6.4540,  -6.1719,  -9.7201]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, BeitForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "# image_path = 'Image_data/Examples/trump.png'\n",
    "# image = Image.open(image_path).convert(\"RGB\")\n",
    "# image_path_GT = 'Image_data/Examples/trump_GT.png'\n",
    "# ground_truth = Image.open(image_path_GT).convert(\"RGB\")\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/beit-base-finetuned-ade-640-640\")\n",
    "model = BeitForSemanticSegmentation.from_pretrained(\"microsoft/beit-base-finetuned-ade-640-640\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "# logits are of shape (batch_size, num_labels, height, width)\n",
    "logits = outputs.logits\n",
    "logits\n",
    "# img = logits_to_image(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3b479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff58954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits to probabilities using softmax\n",
    "probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "# Select the probabilities for the desired class (e.g., class 0)\n",
    "class_probabilities = probabilities[:, 0, :, :]\n",
    "\n",
    "# Convert probabilities to an image\n",
    "class_probabilities_np = class_probabilities.detach().numpy()\n",
    "class_probabilities_np = class_probabilities_np.squeeze()\n",
    "image_array = np.uint8(class_probabilities_np * 255)\n",
    "\n",
    "image = Image.fromarray(image_array, mode=\"L\")  # Create grayscale image\n",
    "\n",
    "# Display or save the image\n",
    "image.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7de6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
