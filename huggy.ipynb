{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a2a6f2-6187-4720-8ecd-51bbc974dbce",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code below was taken from the exact model that I chose to try. \n",
    "It most probably does not cater to al the models on Hugging Face.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12ef78-bc47-42ed-ab0f-a690121c87bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See the video.  Dirk could not get the rgb_to_id function so I stole it from the website:\n",
    "\n",
    "# 2 functions below copied from https://github.com/cocodataset/panopticapi/blob/master/panopticapi/utils.py\n",
    "# Copyright (c) 2018, Alexander Kirillov\n",
    "# All rights reserved.\n",
    "def rgb_to_id(color):\n",
    "    if isinstance(color, np.ndarray) and len(color.shape) == 3:\n",
    "        if color.dtype == np.uint8:\n",
    "            color = color.astype(np.int32)\n",
    "        return color[:, :, 0] + 256 * color[:, :, 1] + 256 * 256 * color[:, :, 2]\n",
    "    return int(color[0] + 256 * color[1] + 256 * 256 * color[2])\n",
    "\n",
    "\n",
    "def id_to_rgb(id_map):\n",
    "    if isinstance(id_map, np.ndarray):\n",
    "        id_map_copy = id_map.copy()\n",
    "        rgb_shape = tuple(list(id_map.shape) + [3])\n",
    "        rgb_map = np.zeros(rgb_shape, dtype=np.uint8)\n",
    "        for i in range(3):\n",
    "            rgb_map[..., i] = id_map_copy % 256\n",
    "            id_map_copy //= 256\n",
    "        return rgb_map\n",
    "    color = []\n",
    "    for _ in range(3):\n",
    "        color.append(id_map % 256)\n",
    "        id_map //= 256\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dc085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "# from see import Segmentors\n",
    "# from see import JupyterGUI\n",
    "from transformers import DetrFeatureExtractor, DetrForSegmentation\n",
    "\n",
    "#The following command dosn't work for dirk so I hacked the above. \n",
    "#from transformers.models.detr.feature_extraction_detr import rgb_to_id\n",
    "\n",
    "from imageio import v3 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310cb6c-1531-47a4-835b-bcf278d499a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers \n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af386d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = \"https://therealdeal.com/wp-content/uploads/2021/08/Trump-Tower-705x503.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "image_path = './see-segment/Image_data/Examples/trump.png'\n",
    "image_path_GT = './see-segment/Image_data/Examples/trump_GT.png'\n",
    "# image_path = \"/path/to/your/image.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "ground_truth = Image.open(image_path_GT).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57ab22-447f-42ba-a3a3-c6e5893d40fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00170d9d-b97f-4520-82d3-82fd2ef61aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.pylab import plt\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ac34d-5532-4c43-a753-90d7343ef8da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d983c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-50-panoptic\")\n",
    "model = DetrForSegmentation.from_pretrained(\"facebook/detr-resnet-50-panoptic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image for the model\n",
    "inputs = feature_extractor(images=[image], return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# use the `post_process_panoptic` method of `DetrFeatureExtractor` to convert to COCO format\n",
    "processed_sizes = torch.as_tensor(inputs[\"pixel_values\"].shape[-2:]).unsqueeze(0)\n",
    "result = feature_extractor.post_process_panoptic(outputs, processed_sizes)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the segmentation is stored in a special-format png\n",
    "panoptic_seg = Image.open(io.BytesIO(result[\"png_string\"]))\n",
    "panoptic_seg = np.array(panoptic_seg, dtype=np.uint8)\n",
    "# retrieve the ids corresponding to each mask\n",
    "panoptic_seg_id = rgb_to_id(panoptic_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb959d20-1bac-4302-882d-7cd53fc4df21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(panoptic_seg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ab334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the numpy array to a PIL Image\n",
    "panoptic_seg_pil = Image.fromarray(panoptic_seg_id)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(panoptic_seg_id)\n",
    "plt.axis(\"off\")  # Turn off axis labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbce42-b3f5-4932-86c9-0c954b5ecaa6",
   "metadata": {},
   "source": [
    "This code below was take from Inference API under the Image Segmentation heading.\n",
    "I was able to extract my API_TOKEN which is apparantly different for everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "API_TOKEN = \"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\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/detr-resnet-50-panoptic\"\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "data = query(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0616a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# from io import BytesIO\n",
    "# from PIL import Image\n",
    "# with Image.open(image_path) as img:\n",
    "#     masks = [d[\"mask\"] for d in data]\n",
    "#     assert img.size == (640, 480)\n",
    "#     mask_imgs = [Image.open(BytesIO(base64.b64decode(mask))) for mask in masks]\n",
    "#     for mask_img in mask_imgs:\n",
    "#         assert mask_img.size == img.size\n",
    "#         assert mask_img.mode == \"L\"  # L (8-bit pixels, black and white)\n",
    "#     first_mask_img = mask_imgs[0]\n",
    "#     min_pxl_val, max_pxl_val = first_mask_img.getextrema()\n",
    "#     assert min_pxl_val >= 0\n",
    "#     assert max_pxl_val <= 255\n",
    "\n",
    "# with Image.open(\"Image_data/Examples/trump.png\") as img:\n",
    "#     masks = [d[\"mask\"] for d in data]\n",
    "#     assertEqual(img.size, (640, 480))\n",
    "#     mask_imgs = [Image.open(BytesIO(base64.b64decode(mask))) for mask in masks]\n",
    "#     for mask_img in mask_imgs:\n",
    "#         assertEqual(mask_img.size, img.size)\n",
    "#         assertEqual(mask_img.mode, \"L\")  # L (8-bit pixels, black and white)\n",
    "#     first_mask_img = mask_imgs[0]\n",
    "#     min_pxl_val, max_pxl_val = first_mask_img.getextrema()\n",
    "#     assertGreaterEqual(min_pxl_val, 0)\n",
    "#     assertLessEqual(max_pxl_val, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de9a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
