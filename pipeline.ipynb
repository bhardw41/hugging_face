{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f9cda4",
   "metadata": {},
   "source": [
    "# Using Pipeline class from Transformers Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adeb273b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b13d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page 0\n",
      "Parsing page 1\n",
      "Parsing page 2\n",
      "Parsing page 3\n",
      "Parsing page 4\n",
      "Parsing page 5\n",
      "Parsing page 6\n",
      "Parsing page 7\n",
      "Parsing page 8\n"
     ]
    }
   ],
   "source": [
    "from SEE_hug import list_of_models\n",
    "model = list_of_models.get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb3e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(model)\n",
    "# models = models[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7cf3a",
   "metadata": {},
   "source": [
    "#### Extract all the images from our dataset and divide them into ground truths and unsegmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1567c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagepath = pathlib.Path('./Images/')\n",
    "images = imagepath.glob('*')\n",
    "inferred = []\n",
    "GT = []\n",
    "for image in images:\n",
    "    if \"GT\" in image.name:\n",
    "        GT.append(image)\n",
    "\n",
    "    elif \"GT\" not in image.name and \"ipy\" not in image.name:\n",
    "        inferred.append(image)\n",
    "GT_paths = sorted(GT)\n",
    "input_paths = sorted(inferred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1a00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Test the generated mask with ground truth using SEE-Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb6855d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ishasharma/Desktop/SEE Git/see-segment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe94e15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from see import Segment_Fitness as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1e2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/Users/ishasharma/anaconda3/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trivial solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`label_ids_to_fuse` unset. No instance will be fused.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trivial solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`label_ids_to_fuse` unset. No instance will be fused.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gave error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trivial solution\n",
      "trivial solution\n"
     ]
    }
   ],
   "source": [
    "fitness_table = []\n",
    "for image_path, GT_path in zip(input_paths, GT_paths):\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # NOTE TO DIRK, why does adding [:,:,0] change the fitness?\n",
    "    GT_image = np.array(Image.open(GT_path).convert(\"RGB\"))[:,:,0]\n",
    "    \n",
    "    # Create subplots for each model's segmented image\n",
    "    fig, axs = plt.subplots(1, len(models))\n",
    "    \n",
    "    fitness = []\n",
    "    # Iterate over the models and display segmented images\n",
    "    \n",
    "    for i, model_name in enumerate(models):\n",
    "        # Initialize an image segmentation pipeline\n",
    "        try:\n",
    "            segmentation_pipeline = pipeline(\"image-segmentation\", model=model_name)\n",
    "            outputs = segmentation_pipeline(image)\n",
    "            inferred_segmentation = outputs[0]['mask']\n",
    "\n",
    "            # Display the segmented image in the corresponding subplot\n",
    "            ax = axs[i] if len(models) > 1 else axs\n",
    "            ax.imshow(inferred_segmentation)\n",
    "            fit = sf.FitnessFunction(np.array(inferred_segmentation), GT_image)\n",
    "            fitness.append(fit[0])\n",
    "        except:\n",
    "            fitness.append(\"NaN\")\n",
    "            print(\"Gave error\")\n",
    "    fitness_table.append(fitness)\n",
    "\n",
    "        # Adjust the layout to avoid overlapping images\n",
    "    fig.tight_layout()\n",
    "\n",
    "        # Show the figure for the current image\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a86a2e-485d-42fb-b4ed-035483d3959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ac772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fitness_table, index = inferred, columns = models)\n",
    "df.index.names = [\"Images\"]\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
