{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f9cda4",
   "metadata": {},
   "source": [
    "# Using Pipeline class from Transformers Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb273b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7cf3a",
   "metadata": {},
   "source": [
    "#### Extract all the images from our dataset and divide them into ground truths and unsegmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1567c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagepath = pathlib.Path('./Images/')\n",
    "images = imagepath.glob('*')\n",
    "inferred = []\n",
    "GT = []\n",
    "for image in images:\n",
    "#     print(dir(image))\n",
    "    \n",
    "    if \"GT\" in image.name:\n",
    "        GT.append(image)\n",
    "#         print(\"GT\" , image.name)\n",
    " \n",
    "    elif \"GT\" not in image.name and \"ipy\" not in image.name:\n",
    "        inferred.append(image)\n",
    "#         print(\"inf\", image.name)\n",
    "GT_paths = sorted(GT)\n",
    "input_paths = sorted(inferred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1a00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Test the generated mask with ground truth using SEE-Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6855d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./see-segment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94e15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from see import Segment_Fitness as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1e2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "models = [\"facebook/mask2former-swin-large-cityscapes-semantic\",\n",
    "          \"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\",\n",
    "          \"apple/deeplabv3-mobilevit-small\"]\n",
    "#           \"facebook/mask2former-swin-large-mapillary-vistas-semantic\"]\n",
    "#           \"Intel/dpt-large-ade\"]\n",
    "row = []\n",
    "GT_images = []\n",
    "input_images = []\n",
    "each_row = []\n",
    "for image_path, GT_path in zip(input_paths[0:1], GT_paths[0:1]):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_images.append(image)\n",
    "    \n",
    "    GT_image = Image.open(GT_path)\n",
    "    GT_images.append(GT_image)\n",
    "    \n",
    "    \n",
    "    # Create subplots for each model's segmented image\n",
    "    fig, axs = plt.subplots(1, len(models))\n",
    "\n",
    "    # Iterate over the models and display segmented images\n",
    "    for i, model_name in enumerate(models):\n",
    "        # Initialize an image segmentation pipeline\n",
    "        segmentation_pipeline = pipeline(\"image-segmentation\", model=model_name)\n",
    "        outputs = segmentation_pipeline(image)\n",
    "        segmented_image = outputs[0]['mask']\n",
    "        each_row.append(segmented_image)\n",
    "        # Display the segmented image in the corresponding subplot\n",
    "        ax = axs[i] if len(models) > 1 else axs\n",
    "        ax.imshow(segmented_image)\n",
    "#         ax.axis('off')\n",
    "    row.append(each_row)\n",
    "    each_row = []\n",
    "    # Adjust the layout to avoid overlapping images\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Show the figure for the current image\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4898a",
   "metadata": {},
   "source": [
    "## Problem\n",
    "When using the fitness function, I get an Assertion Error that says that the sizes of the two images I am trying to comapre are different. I checked the shapes and for some reason shape of all ground truth images is nothing. I am not sure why that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbbadf7-7f24-4dce-aeb2-655846410cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(GT_images[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb243ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(np.array(row[0][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5d5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for counter in range(0,len(inferred)):\n",
    "    for i in range(0,len(models)):\n",
    "        sf.FitnessFunction(np.array(GT_images[counter]), np.array(row[counter][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ef41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
